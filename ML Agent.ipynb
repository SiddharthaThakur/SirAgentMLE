{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58641d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65fbacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use a library like LangChain for the LLM calls, uncomment:\n",
    "# from langchain import OpenAI\n",
    "\n",
    "# For environment variables\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411415ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # Load .env if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b697f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your OpenAI (or other LLM) API Key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\", None)\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"No OpenAI API key found. Please set OPENAI_API_KEY in your environment or .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c8082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Helper function to call LLM\n",
    "##################################################################\n",
    "def call_llm_system(prompt, model=\"gpt-3.5-turbo\", temperature=0.7):\n",
    "    \"\"\"\n",
    "    Simple wrapper for calling the OpenAI ChatCompletion API.\n",
    "    Returns the text of the assistant's response.\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def extract_code_block(text):\n",
    "    \"\"\"\n",
    "    Attempts to find the FIRST triple backtick code block in the text.\n",
    "    Returns just the code inside the backticks, or None.\n",
    "    \"\"\"\n",
    "    pattern = r\"```(.*?)```\"\n",
    "    matches = re.findall(pattern, text, flags=re.DOTALL)\n",
    "    if matches:\n",
    "        return matches[0].strip()\n",
    "    return None\n",
    "\n",
    "def run_code_snippet(code_snippet, function_name, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Dynamically executes a code snippet that *must* define a function\n",
    "    named `function_name`. Then calls that function with `*args, **kwargs`.\n",
    "    \n",
    "    Returns whatever that function returns.\n",
    "    \"\"\"\n",
    "    # Write to a temporary Python file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".py\", delete=False, mode=\"w\") as tmp_file:\n",
    "        tmp_file_path = tmp_file.name\n",
    "        tmp_file.write(code_snippet)\n",
    "\n",
    "    module_name = os.path.splitext(os.path.basename(tmp_file_path))[0]\n",
    "    loaded_module = None\n",
    "    result = None\n",
    "    try:\n",
    "        spec = importlib.util.spec_from_file_location(module_name, tmp_file_path)\n",
    "        loaded_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(loaded_module)\n",
    "\n",
    "        if hasattr(loaded_module, function_name):\n",
    "            func = getattr(loaded_module, function_name)\n",
    "            result = func(*args, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Function '{function_name}' not found in the snippet.\")\n",
    "    finally:\n",
    "        # Clean up\n",
    "        os.remove(tmp_file_path)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f148b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# 1. DataAgent\n",
    "##################################################################\n",
    "class DataAgent:\n",
    "    \"\"\"\n",
    "    - Scans a folder for CSV files.\n",
    "    - Asks LLM how to interpret or merge them if needed.\n",
    "    - Produces a \"combined DataFrame\" or multiple DataFrames.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir=\"data\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.dataframes = {}  # key -> DataFrame\n",
    "    \n",
    "    def run(self):\n",
    "        # 1. Gather CSV files\n",
    "        csv_files = glob.glob(os.path.join(self.data_dir, \"*.csv\"))\n",
    "        if not csv_files:\n",
    "            print(\"[DataAgent] No CSV files found in data folder.\")\n",
    "            return None\n",
    "        \n",
    "        # 2. Summarize file names, ask LLM how to handle them\n",
    "        file_list_str = \"\\n\".join([os.path.basename(f) for f in csv_files])\n",
    "        prompt = (\n",
    "            \"You are a Data Engineer. I have these CSV files:\\n\"\n",
    "            f\"{file_list_str}\\n\\n\"\n",
    "            \"They contain NCAA basketball data (e.g., Teams, Seasons, Seeds, etc.) \"\n",
    "            \"for March Madness predictions. Propose how to read them, interpret them, \"\n",
    "            \"and whether we should merge them into a single DataFrame or keep multiple. \"\n",
    "            \"Provide Python code (in a function named `load_and_merge_data(data_dir)`), \"\n",
    "            \"using pandas. The function should return a single pandas DataFrame if possible, \"\n",
    "            \"or a dictionary of DataFrames if you deem that better.\"\n",
    "        )\n",
    "        llm_response = call_llm_system(prompt)\n",
    "        code_snippet = extract_code_block(llm_response)\n",
    "        if not code_snippet:\n",
    "            # fallback - no code block found\n",
    "            print(\"[DataAgent] No code block found. Will attempt to just load all CSVs individually.\")\n",
    "            for fpath in csv_files:\n",
    "                key = os.path.splitext(os.path.basename(fpath))[0]\n",
    "                self.dataframes[key] = pd.read_csv(fpath)\n",
    "            return self.dataframes\n",
    "        \n",
    "        # 3. Execute code snippet\n",
    "        try:\n",
    "            result = run_code_snippet(code_snippet, \"load_and_merge_data\", self.data_dir)\n",
    "            if isinstance(result, dict):\n",
    "                self.dataframes = result\n",
    "                print(f\"[DataAgent] LLM returned dict of DataFrames: {list(self.dataframes.keys())}\")\n",
    "                return self.dataframes\n",
    "            elif isinstance(result, pd.DataFrame):\n",
    "                self.dataframes[\"merged\"] = result\n",
    "                print(f\"[DataAgent] LLM returned single DataFrame: {result.shape}\")\n",
    "                return self.dataframes\n",
    "            else:\n",
    "                print(\"[DataAgent] Unexpected return type from LLM code. Storing as 'unknown' key.\")\n",
    "                self.dataframes[\"unknown\"] = result\n",
    "                return self.dataframes\n",
    "        except Exception as e:\n",
    "            print(\"[DataAgent] Error executing LLM code:\", e)\n",
    "            print(\"[DataAgent] Falling back to simply loading each CSV individually.\")\n",
    "            for fpath in csv_files:\n",
    "                key = os.path.splitext(os.path.basename(fpath))[0]\n",
    "                self.dataframes[key] = pd.read_csv(fpath)\n",
    "            return self.dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12e520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# 2. ExplorationAgent\n",
    "##################################################################\n",
    "class ExplorationAgent:\n",
    "    \"\"\"\n",
    "    Takes loaded dataframes. Asks LLM for EDA approach or feature inspection. \n",
    "    Potentially returns suggestions or code.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def run(self, dataframes):\n",
    "        # Summarize data shapes & columns\n",
    "        summary = []\n",
    "        for k, df in dataframes.items():\n",
    "            summary.append(f\"DataFrame '{k}': shape={df.shape}, columns={list(df.columns)}\")\n",
    "        summary_str = \"\\n\".join(summary)\n",
    "\n",
    "        # Ask LLM to propose an EDA or data exploration approach\n",
    "        prompt = (\n",
    "            \"You are a data scientist exploring NCAA basketball data. \"\n",
    "            \"Below are the dataframes loaded:\\n\"\n",
    "            f\"{summary_str}\\n\\n\"\n",
    "            \"Propose a quick EDA approach, interesting insights, and potential merges or transformations. \"\n",
    "            \"Provide a rationale, but also supply Python code in a function named `eda_and_insights(dataframes)` \"\n",
    "            \"that uses pandas, matplotlib, or seaborn for EDA. The function can just print or display insights. \"\n",
    "            \"We won't necessarily display plots here, but we want to see how you'd do it.\"\n",
    "        )\n",
    "\n",
    "        llm_response = call_llm_system(prompt)\n",
    "        code_snippet = extract_code_block(llm_response)\n",
    "\n",
    "        return {\n",
    "            \"exploration_plan\": llm_response,\n",
    "            \"code\": code_snippet\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fa48f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# 3. FeatureEngineeringAgent\n",
    "##################################################################\n",
    "class FeatureEngineeringAgent:\n",
    "    \"\"\"\n",
    "    Takes EDA suggestions + data. Asks LLM for feature engineering code.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def run(self, dataframes, eda_suggestions):\n",
    "        # Summarize again, and ask for feature engineering approach\n",
    "        summary = []\n",
    "        for k, df in dataframes.items():\n",
    "            summary.append(f\"'{k}': shape={df.shape}, columns={list(df.columns)}\")\n",
    "        summary_str = \"\\n\".join(summary)\n",
    "\n",
    "        prompt = (\n",
    "            \"You are an ML engineer. We have the following dataframes:\\n\"\n",
    "            f\"{summary_str}\\n\\n\"\n",
    "            \"We want to engineer features for predicting NCAA basketball matchups. \"\n",
    "            \"Here is the EDA's suggestions:\\n\"\n",
    "            f\"{eda_suggestions}\\n\\n\"\n",
    "            \"Provide a function named `feature_engineering(dataframes)` in Python that:\\n\"\n",
    "            \"- Possibly merges or transforms them.\\n\"\n",
    "            \"- Creates new features.\\n\"\n",
    "            \"- Returns a single DataFrame with the features and a 'target' column (if available). \"\n",
    "            \"If there's no explicit target, you can randomly create one or deduce it from the data. \"\n",
    "            \"Only return the final DataFrame.\"\n",
    "        )\n",
    "\n",
    "        llm_response = call_llm_system(prompt)\n",
    "        code_snippet = extract_code_block(llm_response)\n",
    "        if not code_snippet:\n",
    "            print(\"[FeatureEngineeringAgent] No code snippet found. Returning dataframes as is.\")\n",
    "            # fallback: pick first DF if we can't do better\n",
    "            key0 = list(dataframes.keys())[0]\n",
    "            df = dataframes[key0].copy()\n",
    "            # If no target, add a random one\n",
    "            if \"target\" not in df.columns:\n",
    "                df[\"target\"] = np.random.randint(0, 2, len(df))\n",
    "            return df\n",
    "\n",
    "        # Execute code snippet\n",
    "        try:\n",
    "            result = run_code_snippet(code_snippet, \"feature_engineering\", dataframes)\n",
    "            if isinstance(result, pd.DataFrame):\n",
    "                print(f\"[FeatureEngineeringAgent] Feature engineering returned DataFrame {result.shape}\")\n",
    "                return result\n",
    "            else:\n",
    "                print(\"[FeatureEngineeringAgent] Unexpected return type from LLM code. Converting to DataFrame forcibly.\")\n",
    "                return pd.DataFrame(result)\n",
    "        except Exception as e:\n",
    "            print(\"[FeatureEngineeringAgent] Error executing LLM code snippet:\", e)\n",
    "            # fallback\n",
    "            key0 = list(dataframes.keys())[0]\n",
    "            df = dataframes[key0].copy()\n",
    "            if \"target\" not in df.columns:\n",
    "                df[\"target\"] = np.random.randint(0, 2, len(df))\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "037f4148",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# 4. ModelSelectionAgent\n",
    "##################################################################\n",
    "class ModelSelectionAgent:\n",
    "    \"\"\"\n",
    "    Asks LLM to pick a model or architecture and produce code to train it.\n",
    "    Runs the code, obtains the model object, returns it.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def run(self, df):\n",
    "        # Summarize\n",
    "        shape = df.shape\n",
    "        cols = list(df.columns)\n",
    "        prompt = (\n",
    "            f\"You are an ML expert. We have a DataFrame shape={shape}, columns={cols}.\\n\"\n",
    "            \"We want to do classification for the 'target' column. Provide Python code in a function named \"\n",
    "            \"`build_and_train_model(X_train, y_train, X_val, y_val)` that:\\n\"\n",
    "            \"1) Splits the data if not already split.\\n\"\n",
    "            \"2) Builds a recommended model (could be scikit-learn or a simple neural network).\\n\"\n",
    "            \"3) Trains it.\\n\"\n",
    "            \"4) Returns the trained model. \"\n",
    "            \"We want to see your best guess. Also consider we might have limited data typical of Kaggle March Madness (tens of thousands of rows).\"\n",
    "        )\n",
    "\n",
    "        llm_response = call_llm_system(prompt)\n",
    "        code_snippet = extract_code_block(llm_response)\n",
    "        if not code_snippet:\n",
    "            print(\"[ModelSelectionAgent] No code snippet found. Generating fallback logistic regression.\")\n",
    "            code_snippet = self.fallback_code()\n",
    "\n",
    "        # We do our own train/val split externally for better control:\n",
    "        # We'll pass them to the LLM's function. \n",
    "        # But if the LLM tries to split inside the function, that's okayâ€”it can do so again.\n",
    "        # We'll just override or pass the split in anyway.\n",
    "\n",
    "        # We'll do a local split:\n",
    "        if \"target\" not in df.columns:\n",
    "            # fallback\n",
    "            df[\"target\"] = np.random.randint(0,2,len(df))\n",
    "\n",
    "        X = df.drop(columns=[\"target\"])\n",
    "        y = df[\"target\"]\n",
    "\n",
    "        # Make train/val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        try:\n",
    "            model = run_code_snippet(code_snippet, \"build_and_train_model\", X_train, y_train, X_val, y_val)\n",
    "            return model, (X_val, y_val)\n",
    "        except Exception as e:\n",
    "            print(\"[ModelSelectionAgent] Error running LLM-provided code snippet:\", e)\n",
    "            # fallback code\n",
    "            code_snippet = self.fallback_code()\n",
    "            model = run_code_snippet(code_snippet, \"build_and_train_model\", X_train, y_train, X_val, y_val)\n",
    "            return model, (X_val, y_val)\n",
    "\n",
    "    def fallback_code(self):\n",
    "        \"\"\"\n",
    "        Just in case the LLM code fails, use a minimal logistic regression snippet.\n",
    "        \"\"\"\n",
    "        code = \"\"\"\\\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def build_and_train_model(X_train, y_train, X_val, y_val):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\"\"\"\n",
    "        return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28291c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# 5. EvaluationAgent\n",
    "##################################################################\n",
    "class EvaluationAgent:\n",
    "    \"\"\"\n",
    "    Evaluates the trained model, can feed results back to LLM for analysis or next-step suggestions.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def run(self, model, X_val, y_val):\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            proba = model.predict_proba(X_val)\n",
    "            ll = log_loss(y_val, proba)\n",
    "        else:\n",
    "            preds = model.predict(X_val)\n",
    "            # naive approach to approximate proba\n",
    "            proba = np.column_stack([1 - preds, preds])\n",
    "            ll = log_loss(y_val, proba)\n",
    "        preds = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "\n",
    "        print(f\"[EvaluationAgent] log_loss={ll:.4f}, accuracy={acc:.4f}\")\n",
    "        return {\"log_loss\": ll, \"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd31f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# 6. Coordinator\n",
    "##################################################################\n",
    "class FullAutomationCoordinator:\n",
    "    \"\"\"\n",
    "    Orchestrates the entire pipeline with Agents:\n",
    "    1. DataAgent -> load or merge data\n",
    "    2. ExplorationAgent -> EDA suggestions\n",
    "    3. FeatureEngineeringAgent -> create final features + target\n",
    "    4. ModelSelectionAgent -> build and train model\n",
    "    5. EvaluationAgent -> measure performance\n",
    "    6. (Optional) Feedback loop or multiple iterations\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir=\"data\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_agent = DataAgent(data_dir=data_dir)\n",
    "        self.exploration_agent = ExplorationAgent()\n",
    "        self.feature_engineering_agent = FeatureEngineeringAgent()\n",
    "        self.model_selection_agent = ModelSelectionAgent()\n",
    "        self.evaluation_agent = EvaluationAgent()\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        # 1. Load data\n",
    "        dataframes = self.data_agent.run()\n",
    "        if not dataframes:\n",
    "            print(\"[Coordinator] No data loaded. Pipeline ends.\")\n",
    "            return\n",
    "\n",
    "        # 2. Exploration\n",
    "        eda_info = self.exploration_agent.run(dataframes)\n",
    "        # We *could* run the EDA code snippet just for demonstration:\n",
    "        if eda_info[\"code\"]:\n",
    "            try:\n",
    "                run_code_snippet(eda_info[\"code\"], \"eda_and_insights\", dataframes)\n",
    "            except Exception as e:\n",
    "                print(\"[Coordinator] EDA code snippet failed:\", e)\n",
    "\n",
    "        # 3. Feature Engineering\n",
    "        df_features = self.feature_engineering_agent.run(dataframes, eda_info[\"exploration_plan\"])\n",
    "        if df_features is None or len(df_features) == 0:\n",
    "            print(\"[Coordinator] FeatureEngineeringAgent returned empty. Exiting.\")\n",
    "            return\n",
    "\n",
    "        # 4. Model Selection\n",
    "        model, val_data = self.model_selection_agent.run(df_features)\n",
    "        if model is None:\n",
    "            print(\"[Coordinator] No model returned. Exiting.\")\n",
    "            return\n",
    "        \n",
    "        # 5. Evaluation\n",
    "        X_val, y_val = val_data\n",
    "        metrics = self.evaluation_agent.run(model, X_val, y_val)\n",
    "        print(\"[Coordinator] Final metrics:\", metrics)\n",
    "\n",
    "        # 6. Could add a loop for refinement\n",
    "        # e.g. feed metrics back to LLM, ask for improved feature eng or modeling\n",
    "        # We'll stop here for demonstration.\n",
    "        print(\"[Coordinator] Pipeline complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849cce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinator = FullAutomationCoordinator(data_dir=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b7c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinator.run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
